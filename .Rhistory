gbmFit <- train(classe ~ ., data = training_clear_1,
method = "rf",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "rf",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
remove
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "rf",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
dim(training)
dim(training_clear_1)
clear_nzv$nzv
sum(clear_nzb)
sum(clear_nzv)
sum(clear_nzv$nzv)
dim(training_clear_1)
for(i in 1:length(remove)){
print(is.na(training[,i])/length(training[,i]))
}
for(i in 1:length(remove)){
print(sum(is.na(training[,i]))/length(training[,i]))
}
for(i in 1:length(remove)){
print(sum(is.NAN(training[,i]))/length(training[,i]))
}
for(i in 1:length(remove)){
print(sum(is.NA(training[,i]))/length(training[,i]))
}
head(training)
head(is.NA(training))
head(is.na(training))
for(i in 1:length(remove)){
sum(is.NA(training[,i]))/length(training[,i])
}
for(i in 1:length(remove)){
sum(is.na(training[,i]))/length(training[,i])
}
for(i in 1:length(remove)){
print(sum(is.na(training[,i]))/length(training[,i]))
}
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
for(i in 1:length(remove)){
if(sum(is.na(training[,i]))/length(training[,i])>0.9){
remove[,i]=TRUE
}
}
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "rf",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
for(i in 1:length(remove)){
if(sum(is.na(training[,i]))/length(training[,i])>0.9){
remove[,i]=TRUE
}
}
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
for(i in 1:length(remove)){
if(sum(is.na(training[,i]))/length(training[,i])>0.9){
remove[i]=TRUE
}
}
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
for(i in 1:length(remove)){
if(sum(is.na(training[,i]))/length(training[,i])>0.9){
remove[i]=TRUE
}
}
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
for(i in 1:length(remove)){
if(sum(is.na(training[,i]))/length(training[,i])>0.9){
remove[i]=TRUE
}
}
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
sum(remove)
remove
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 10)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
training_clear_1
head(intraining)
head(trainging_clear_1)
head(training_clear_1)
!remove
head(training_clear_1)
head(training_clear_1$classe)
training_clear_1$classe
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 3)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
library(caret)
library(e1071)
library(gbm)
library(adabag)
library(C50)
convert.magic <- function(x, y=NA) {
for(i in 1:length(y)) {
if (y[i] == "integer") {
x[i] <- as.integer(x[[i]])
}
if (y[i] == "factor")
x[i] <- as.factor(x[[i]])
if (y[i] == "numeric")
x[i] <- as.numeric(x[[i]])
}
return(x)
}
data=read.csv(file="pml-training.csv")
head(data)
data$classe<-as.factor(data$classe)
set.seed(998)
inTraining <- createDataPartition(data$classe, p = .75, list = FALSE)
training <- data[ inTraining,]
testing  <- data[-inTraining,]
clear_nzv=nearZeroVar(training, saveMetrics=TRUE)
remove=clear_nzv$nzv
remove[1:7]=TRUE
for(i in 1:length(remove)){
if(sum(is.na(training[,i]))/length(training[,i])>0.9){
remove[i]=TRUE
}
}
training_clear_1=training[,!remove]
testing_clear_1=testing[,!remove]
fitControl <- trainControl(## 3-fold CV
method = "repeatedcv",
number = 3,
## repeated 3 times
repeats = 3)
gbmFit <- train(classe ~ ., data = training_clear_1,
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmpredict=predict(gbmFit, newdata=testing_clear_1,na.action = na.pass)
confusionMatrix(gbmpredict,testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
gbmpredict_test=predict(gbmFit, newdata=data_real_test,na.action = na.pass)
testing_clear_1
training_clear_1
dim(training_clear_1)
modFitA1 <- rpart(classe ~ ., data=myTraining, method="class")
modFitA1 <- rpart(classe ~ ., data=inTraining, method="class")
gbmFit <- train(classe ~ ., data = as.data.frame(training_clear_1),
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
gbmFit <- train(classe ~ ., data = as.data.frame(training_clear_1),
method = "gbm",
trControl = fitControl,
## This last option is actually one
## for gbm() that passes through
verbose = FALSE)
modFitA1 <- rpart(classe ~ ., data=training_clear_1, method="class")
modFitA1
predictionsA1 <- predict(modFitA1, testing_clear_1, type = "class")
confusionMatrix(predictionsA1, myTesting$classe)
confusionMatrix(predictionsA1, testing_clear_1$classe)
classes=laply(training_clear_1,class)
data_real_test=read.csv(file="pml-testing_1.csv")
data_real_test=convert.magic(data_real_test[,!remove], classes)
predictionsA1 <- predict(modFitA1, data_real_test, type = "class")
predictionsA1
?rpart
predict(C5.0Fit1, newdata = data_real_test)
